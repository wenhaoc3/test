# -*- coding: utf-8 -*-
"""1D_ade_120-Test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I3J4_IpKdorFJJNg5Pp_it0oKH7IwmNe
"""

import numpy as np
import matplotlib.pyplot as plt
import datetime

import torch
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import math
import numpy as np
import torch.nn.functional as F
import h5py


import scipy.linalg as spl



import numpy as np
import matplotlib.pyplot as plt
from scipy.special import erfc
from scipy.integrate import solve_ivp
from scipy.interpolate import interp1d
from scipy.optimize import least_squares
from scipy import io
from scipy import sparse
from scipy.optimize import minimize
import h5py
import scipy.linalg as spl

import time
import heapq
import itertools

# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    device = torch.device("cuda")
    print("GPU is available")
else:
    device = torch.device("cpu")
    print("GPU is not available")
# torch.backends.cudnn.enabled = True
# torch.backends.cudnn.benchmark = True

rl2e_Sg=lambda yest,yref:spl.norm(yest-yref,2)/spl.norm(yref,2)
rl2e_p=lambda yest,yref:spl.norm(yest-yref,2)/spl.norm((yref-1),2)
# vp = lambda y_preds: np.var(y_preds, axis=0)

#residual dataset
N_R_train=10
N_R_test=10

#total dataset, training_set_1
N_train=500
N_test=20

#real test
N_ts=3


#N_eta
Nuterm_Sg =60
Nuterm_p = 150
Nuterm_k= 20

#mesh
N_rt = 100
N_rx = 100
Nodes=N_rx+1

# for N_train=0
# w2=0
# w2=10
# a1=0
# a2=0
# a1=1e4/(N_rt*Nodes)
# a2=1e4/(N_rt*Nodes)
# a3=1e4/(N_rt*Nodes)
# a4=1e4/(N_rt*Nodes)

batch_size = N_train
# n_epoch = 30000
# lr = 1e-3
# hidden_size = 2000
# regulerization = 0
# N_net=10

# Sg_stopping=300




#parameters
L=4
T=10



dt=T/N_rt
dx=L/N_rx

# k_m=2e-14
q_g_m=8.87/100

#testing point
# k_c=1.05*k_m
q_g_c=q_g_m


p_in = 2.921*10**7 # Initial pressure
mu_g = 3.95*10**-5       # CO2 viscosity
mu_w = 2.535*10**-4      # Brine viscosity
phi = 0.15
N=2
q_g_place=(N_rx-1)//N

# Create the coordinate of the nodes
xnode = np.linspace(0, L, Nodes)

K = 2*10**-14
l = 0.5*L     # For the Robin B.C.
Sg_inf = 0    # Sg value at the infinity x (Robin B.C.)
p_in = 2.921*10**7 # Initial pressure
p_inf = 2.921*10**7 # p value at the infinity x (Robin B.C.)

def CO2_picard(N_rt,N_rx,k,q_g):

  # Parameters
  # K = 2*10**-14           # Aquifer permeability
  # mu_g = 3.95*10**-5       # CO2 viscosity
  # mu_w = 2.535*10**-4      # Brine viscosity
  # phi = 0.15               # Porosity
  # q_g = 8.87/50             # CO2 injection rate (8.87 in paper)
  # p_in = 2.921*10**7 # Initial pressure
  # L = 4         # Length of the domain
  l = 0.5*L     # For the Robin B.C.
  Sg_inf = 0    # Sg value at the infinity x (Robin B.C.)
  p_inf = 2.921*10**7 # p value at the infinity x (Robin B.C.)
  # Nx = 100       # Number of the control volumes
  # Nodes = Nx + 1  # Number of the nodes
  # Nt = 100        # Number of time steps
  # dx = L / Nx     # Spatial step size
  # dt = 0.01     # Time step size
  TG = 200000         # Set the time interval
  q_g_place=(N_rx-1)//2
  Nx=N_rx
  Nt=N_rt

  # q_g_place=(Nx-1)//2
  sum_mat_ex_g = np.zeros((Nt,Nx+1)) # Set the matrix to save all CO2 solution needed
  sum_mat_ex_p = np.zeros((Nt,Nx+1)) # Set the matrix to save all pressure solution needed
  iteration = 10000
  threshold = 10**-4
  # a = 1e-14
  # n = 1.8

  # Create the coordinate of the nodes
  # xnode = np.linspace(0, L, Nodes)

  # k
  # k = K+a*np.sin(xnode*n*np.pi/L)

  # Initial condition
  Sg = np.zeros(Nodes)  # Sg(x,0) = 0
  p = p_in + np.zeros(Nodes)  # p(x,0) = 2.921*10**7

  t = [] # Set the matrix to save the time needed

  Sg_init = np.zeros(Sg.size-2)
  Sg_next = np.zeros(Sg.size-2)
  p_next = np.zeros(p.size-2)

  # A = - K*dt/phi/mu_w/dx**2
  # B =   K*dt/2/phi/mu_w/dx**2
  # C =   K*dt/2/phi/mu_g/dx**2

  # Solve the equation in different time by the explicit method
  # fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))

  for j in range(Nt):
      # Solve Sg first

      if j==0:
          t.append(j*dt)
          c_count=0
          for i in range(len(xnode)):
              sum_mat_ex_g[c_count][i]=Sg[i] # Put the I.C. into the answer
              sum_mat_ex_p[c_count][i]=p[i]

          # # Plot the result
          # time = round(j*dt,1)

          # ax1.plot(xnode,sum_mat_ex_g[c_count],label = str(time))
          # ax1.axis([0,L,0,1.2])
          # ax1.set_xlabel('x')
          # ax1.set_ylabel('Sg')
          # ax1.legend()

          # ax2.plot(xnode,sum_mat_ex_p[c_count],label = str(time))
          # ax2.set_xlabel('x')
          # ax2.set_ylabel('p')
          # ax2.legend()

          c_count=c_count+1

      else:
          for i in range(len(Sg_init)):
              Sg_init[i] = Sg[i+1]

          for m in range(iteration):
              # Calculate the pressure in the new iteration
              Pm = np.zeros((p_next.size,p_next.size))

              for i in range(len(p_next)):
                  if i==0: # For the first row of stiffness matrix
                      Pm[i][i] = (l/(dx+l))*((mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]) - ((mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]+(mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1])
                      Pm[i][i+1] = (mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]

                  elif i==len(p_next)-1: # For the last row of stiffness matrix
                      Pm[i][i] = (l/(dx+l))*((mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]) - ((mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]+(mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1])
                      Pm[i][i-1] = (mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]
                  else:
                      Pm[i][i] = -((mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]+(mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1])
                      Pm[i][i-1] = (mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]+(mu_g*(1-Sg[i])+mu_w*Sg[i])*k[i]
                      Pm[i][i+1] = (mu_g*(1-Sg[i+2])+mu_w*Sg[i+2])*k[i+2]+(mu_g*(1-Sg[i+1])+mu_w*Sg[i+1])*k[i+1]

              # Build the matrix on the right hand side
              Pm_right = np.zeros(len(p_next))

  #             Pm_right = p[1:-1].copy() - (Pm @ p[1:-1]).copy()


              # B.C. of p
              Pm_right[0] = - (dx/(dx+l))*((mu_g*(1-Sg[1])+mu_w*Sg[1])*k[1]+(mu_g*(1-Sg[0])+mu_w*Sg[0])*k[0])*p_inf # First point
              Pm_right[Nodes-3] = - (dx/(dx+l))*((mu_g*(1-Sg[Nodes-1])+mu_w*Sg[Nodes-1])*k[Nodes-1]+(mu_g*(1-Sg[Nodes-2])+mu_w*Sg[Nodes-2])*k[Nodes-2])*p_inf # Final point

              Pm_right -= (Pm @ p[1:-1]).copy()
              Pm_right[q_g_place] -= q_g*(2*mu_w*mu_g*dx**2)

              p_next=np.linalg.solve(Pm,Pm_right)

              for i in range(len(p_next)):
                  p[i+1] += p_next[i]
  #                 p[i+1] = p_next[i]

              p[0] = (l/(dx+l))*p[1].copy() + (dx/(dx+l))*p_inf
              p[-1] = (l/(dx+l))*p[-2].copy() + (dx/(dx+l))*p_inf

              # Calculate the pressure in the new iteration
              Sgm = np.zeros((Sg_next.size,Sg_next.size))

              for i in range(len(Sg_next)):
                  if i==0: # For the first row of stiffness matrix
                      Sgm[i][i] = (-(mu_w+mu_g)*k[i+1]*(p[i+2]-2*p[i+1]+p[i])+2*phi*(2*mu_w*mu_g*dx**2)/dt) + (l/(dx+l))*((mu_w+mu_g)*k[i]*(p[i+1]-p[i]))
                      Sgm[i][i+1] = -(mu_w+mu_g)*k[i+2]*(p[i+2]-p[i+1])

                  elif i==len(p_next)-1: # For the last row of stiffness matrix
                      Sgm[i][i] = (l/(dx+l))*(-(mu_w+mu_g)*k[i+2]*(p[i+2]-p[i+1])) + (-(mu_w+mu_g)*k[i+1]*(p[i+2]-2*p[i+1]+p[i])+2*phi*(2*mu_w*mu_g*dx**2)/dt)
                      Sgm[i][i-1] = (mu_w+mu_g)*k[i]*(p[i+1]-p[i])
                  else:
                      Sgm[i][i] = (-(mu_w+mu_g)*k[i+1]*(p[i+2]-2*p[i+1]+p[i])+2*phi*(2*mu_w*mu_g*dx**2)/dt)
                      Sgm[i][i-1] = (mu_w+mu_g)*k[i]*(p[i+1]-p[i])
                      Sgm[i][i+1] = -(mu_w+mu_g)*k[i+2]*(p[i+2]-p[i+1])

              # Build the matrix on the right hand side
              Sgm_right = np.zeros(len(Sg_next))

              # B.C. of Sg
              Sgm_right[0] = - (dx/(dx+l))*((mu_w+mu_g)*k[0]*(p[1]-p[0]))*Sg_inf
              Sgm_right[Nodes-3] = - (dx/(dx+l))*(-(mu_w+mu_g)*k[Nodes-1]*(p[Nodes-1]-p[Nodes-2]))*Sg_inf


              for i in range(len(Sgm_right)):
                  Sgm_right[i] = 4*mu_w*mu_g*dx**2*phi/dt*Sg_init[i] - mu_g*k[i+2]*(p[i+2]-p[i+1])-mu_g*k[i+1]*(p[i+2]-2*p[i+1]+p[i])+mu_g*k[i]*(p[i+1]-p[i])-(mu_w+mu_g)*k[i]*(p[i+1]-p[i])*Sg[i] - (-(mu_w+mu_g)*k[i+1]*(p[i+2]-2*p[i+1]+p[i])+2*phi*(2*mu_w*mu_g*dx**2)/dt)*Sg[i+1] +(mu_w+mu_g)*k[i+2]*(p[i+2]-p[i+1])*Sg[i+2]
      #             Sgm_right[i] = Sg[i] -B*(p[i+2]-2*p[i+1]+p[i])
      #             Sgm_right= Sg_init+B/2*(p[i+1]-2*p[i]+p[i-1])

              # B.C. of p
              Sgm_right[q_g_place] += 2*mu_w*mu_g*dx**2*q_g

              Sg_next=np.linalg.solve(Sgm,Sgm_right)

              for i in range(len(Sg_next)):
                  Sg[i+1] += Sg_next[i]

              Sg[0] = (l/(dx+l))*Sg[1].copy() + (dx/(dx+l))*Sg_inf
              Sg[-1] = (l/(dx+l))*Sg[-2].copy() + (dx/(dx+l))*Sg_inf

              if  np.max(np.absolute(Sg_next)) > threshold or np.max(np.absolute(p_next)) > threshold: # np.max(np.absolute(Sg_next))

                  continue

              else:

                  for i in range(len(xnode)): # Not consider the B.C.
                      sum_mat_ex_g[c_count][i]=Sg[i] # Save the solution needed
                      sum_mat_ex_p[c_count][i]=p[i]

  #                 if np.max(Sg)>=0.95:
  #                     print(np.max(Sg))
  #                     print(np.max(p))
  #                     q_g=0
  #                     print(c_count)

                  # # Plot the result
                  # time = round(j*dt,3)

                  # ax1.plot(xnode,sum_mat_ex_g[c_count],label = str(time))
                  # ax1.axis([0,L,0,1.2])
                  # ax1.set_xlabel('x')
                  # ax1.set_ylabel('Sg')
                  # #ax1.legend()

                  # ax2.plot(xnode,sum_mat_ex_p[c_count],label = str(time))
                  # ax2.set_xlabel('x')
                  # ax2.set_ylabel('p')
                  # #ax2.legend()

                  c_count=c_count+1

                  # print(c_count)

                  break


  return sum_mat_ex_g,sum_mat_ex_p/p_in

def samples(N_mc,N_rt,N_rx,k_c,q_g_c,min_coef,max_coef,seed=0):     #generate ui
    np.random.seed(seed)
    # k_min = min_coef * kc
    # k_max = max_coef * kc
    # k_mc = k_min + np.random.uniform(0,1,N_mc)*(k_max-k_min)   # vector of random D coefficients
    # n_min = min_coef * n_c
    # n_max = max_coef * n_c
    # n_mc = n_min + np.random.uniform(0,1,N_mc)*(n_max-n_min)   # vector of random V coefficients
    q_g_min = min_coef * q_g_c
    q_g_max = max_coef * q_g_c
    q_g_mc = q_g_min + np.random.uniform(0,1,N_mc)*(q_g_max-q_g_min)   # vector of random V coefficients
    Sg_list = np.zeros((N_mc,N_rt*Nodes))  #node=Nx+1
    p_list = np.zeros((N_mc,N_rt*Nodes))
    # k_list= np.zeros((N_mc,Nodes))
    for i in range(N_mc):
        Sg_i,p_i = CO2_picard(N_rt,N_rx,k_c[i],q_g_mc[i])
        Sg_list[i]=Sg_i.flatten()
        p_list[i]=p_i.flatten()
        # k_list[i]=k_i

    return Sg_list,p_list,q_g_mc

def samples_qg(N_mc,N_rt,N_rx,q_g_c,min_coef,max_coef,seed=0):     #generate ui
    np.random.seed(seed)
    q_g_min = min_coef * q_g_c
    q_g_max = max_coef * q_g_c
    q_g_mc = q_g_min + np.random.uniform(0,1,N_mc)*(q_g_max-q_g_min)   # vector of random V coefficients
    return q_g_mc

def covariance_function_k(x, x_prime, sigma_y_squared=1, l=L/5):
    return sigma_y_squared * np.exp(-(x - x_prime)**2 / (l**2))

def samples_k(N_k,seed=0):
    global K
    np.random.seed(seed)
    cov_k = np.zeros((Nodes, Nodes))
    for i in range(Nodes):
        for j in range(Nodes):
            cov_k[i, j] = covariance_function_k(xnode[i], xnode[j])
    Psiu_k,val_k=eigenpairs_k(cov_k)
    # plot_tx(cov_k,'Nodes','Nodes','cov_k')
    assert np.min(val_k)>=0
    # plot_ln(val_k,log_scale=True)
    k=np.zeros((N_k,Nodes))
    xi_k=np.zeros((N_k,Nuterm_k))
    for i in range(N_k):
      xi_k[i] = np.random.normal(0, 1, Nuterm_k)
      k[i]=K*np.exp(Psiu_k[:, :Nuterm_k] @ xi_k[i].T).T
    assert np.min(k)>0
    return k, xi_k



def eigenpairs_k(cov):                   #calculate the eigenvector times square eigenvalue(psiu), eigenvalue(val) and meanu
    val,vec = np.linalg.eigh(cov+np.sqrt(np.finfo(float).eps)* np.eye(cov.shape[0]))
    idx = val.argsort()[::-1]
    val = val[idx]
    vec= vec[:,idx]
    val_diag = np.diag(val)
    Psiu = vec @ np.sqrt(val_diag)
    return Psiu, val

def eigenpairs(ui):                   #calculate the eigenvector times square eigenvalue(psiu), eigenvalue(val) and meanu
    mean = np.mean(ui,axis=0)
    cov = np.cov(ui.reshape((ui.shape[0],-1)).T)
    val,vec = np.linalg.eigh(cov+np.sqrt(np.finfo(float).eps)* np.eye(cov.shape[0]))
    idx = val.argsort()[::-1]
    val = val[idx]
    vec= vec[:,idx]
    val_diag = np.diag(val)
    Psiu = vec @ np.sqrt(val_diag)
    return Psiu, mean, val,cov

def plot_tx(u,xlabel,ylabel,title=""):
    # plot R map for eta_ref
    plt.figure(figsize=(8, 8))
    fig, ax = plt.subplots()
    cax = ax.imshow(u, cmap='viridis', interpolation='nearest', origin='lower')
    ax.xaxis.set_major_locator(plt.MaxNLocator(nbins=5))
    plt.colorbar(cax)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    ax.set_title(title)
    safe_title = title.replace(' ', '_').translate({ord(i): None for i in '\\/:*?"<>|'})
    filename = f"{safe_title}.png"
    plt.savefig(filename, dpi=300)
    plt.show()

def plot_ln(*arrays,title="",log_scale=False):
  plt.figure(figsize=(10, 5))

  if len(arrays) == 1:
      # If there's only one array, generate index for x-axis and use the array for y-axis
      x_values = np.arange(1, len(arrays[0]) + 1)
      y_values = arrays[0]
  elif len(arrays) == 2:
      # If there are two arrays, use the first for x-axis and the second for y-axis
      x_values = arrays[0]
      y_values = arrays[1]

  plt.plot(x_values, y_values, marker='o')
  if log_scale:
    plt.yscale('log')
  safe_title = title.replace(' ', '_').translate({ord(i): None for i in '\\/:*?"<>|'})
  filename = f"{safe_title}.png"
  plt.savefig(filename, dpi=300)
  plt.show()



def plot_losses(train_loss, test_loss, filename):
    epochs = range(len(train_loss))

    plt.figure(figsize=(10, 5))
    plt.plot(epochs, train_loss, label='Train Loss', marker='o')
    plt.plot(epochs, test_loss, label='Test Loss', marker='x')

    plt.title('Train vs Test Loss per Epoch')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.yscale('log')  # Set the y-axis to a logarithmic scale
    plt.legend()
    plt.grid(True)
    plt.savefig(filename, dpi=300)
    plt.show()

def plot_predictions_vs_reference(predicted, reference, filename):
    plt.figure(figsize=(8, 6))
    plt.scatter(reference, predicted, alpha=0.7)
    plt.title('Predicted vs. Reference Values')
    plt.xlabel('Reference Values')
    plt.ylabel('Predicted Values')
    plt.grid(True)
    plt.savefig(filename, dpi=300)
    plt.show()

def kle_mean_error(x_pred, x_ref, title,single_pred=False, if_p=False):
    KLE_x = np.zeros(len(x_ref))

    if single_pred:
        # Calculate KLE error with a single reference
        if if_p:
            for i in range(len(x_ref)):
                KLE_x[i] = rl2e_p(x_pred, x_ref[i])
            # x_l = (x_pred - x_ref[np.argmax(KLE_x)]).reshape((N_rt, Nodes))
            # plot_tx(x_pred.reshape((N_rt, Nodes)), 'Nx', 'Nt',f"{title} prediction" )
        else:
            for i in range(len(x_ref)):
                KLE_x[i] = rl2e_Sg(x_pred, x_ref[i])
            # x_l = (x_pred - x_ref[np.argmax(KLE_x)]).reshape((N_rt, Nodes))
            # plot_tx(x_pred.reshape((N_rt, Nodes)), 'Nx', 'Nt',f"{title} prediction" )

    else:
        if if_p:
        # Calculate KLE error with multiple references
            for i in range(len(x_ref)):
                KLE_x[i] = rl2e_p(x_pred[i], x_ref[i])
            # x_l = (x_pred[np.argmax(KLE_x)] - x_ref[np.argmax(KLE_x)]).reshape((N_rt, Nodes))
            # plot_tx(x_pred[np.argmax(KLE_x)].reshape((N_rt, Nodes)), 'Nx', 'Nt',f"{title} prediction" )
        else:
            for i in range(len(x_ref)):
                KLE_x[i] = rl2e_Sg(x_pred[i], x_ref[i])
            # x_l = (x_pred[np.argmax(KLE_x)] - x_ref[np.argmax(KLE_x)]).reshape((N_rt, Nodes))
            # plot_tx(x_pred[np.argmax(KLE_x)].reshape((N_rt, Nodes)), 'Nx', 'Nt',f"{title} prediction" )

    # plot_tx(x_ref[np.argmax(KLE_x)].reshape((N_rt, Nodes)), 'Nx', 'Nt',f"{title} ref" )
    # plot_ln(KLE_x,title=f"{title} error deviation",log_scale=True)
    # plot_tx(x_l, 'Nx', 'Nt', title)

    return np.argmax(KLE_x), np.max(KLE_x), np.mean(KLE_x)

def res(eta_1,K_1,q_g_1):
    #for test
    eta_Sg_1=eta_1[:(N_train*Nuterm_Sg)].reshape(N_train,Nuterm_Sg)
    eta_p_1=eta_1[(N_train*Nuterm_Sg):].reshape(N_train,Nuterm_p)
    # Sg_pred=np.zeros((len(eta_Sg),N_rt,Nodes))
    # p_pred=np.zeros((len(eta_Sg),N_rt,Nodes))
    Sg_pred=(meanu_Sg+ (Psiu_Sg[:,:Nuterm_Sg] @ eta_Sg_1.T).T).reshape(len(eta_Sg_1),N_rt,Nodes)
    p_pred=p_in*(meanu_p+ (Psiu_p[:,:Nuterm_p] @ eta_p_1.T).T).reshape(len(eta_Sg_1),N_rt,Nodes)

    # Tol_add_x=np.zeros((len(eta_Sg),N_rt-1,N_rx))
    # Sg_minus_t=np.zeros((len(eta_Sg),N_rt-1,N_rx-1))
    # p_minus_x=np.zeros((len(eta_Sg),N_rt-1,N_rx))
    K_1_expended = K_1.unsqueeze(1)
    # Tol= (mu_g+(mu_w-mu_g)*Sg_pred)*K_1_expended
    # Tol1=((mu_g+mu_w)*Sg_pred-mu_g)*K_1_expended
    Tol2=(1-Sg_pred)*K_1_expended
    Tol3=Sg_pred*K_1_expended

    Sg_minus_t = Sg_pred[:, 1:, 1:-1] - Sg_pred[:, :-1, 1:-1]
    # Tol_add_x = Tol[:, 1:, 1:] + Tol[:, 1:, :-1]
    # Tol1_add_x = Tol1[:, 1:, 1:] + Tol1[:, 1:, :-1]
    Tol2_add_x = Tol2[:, 1:, 1:] + Tol2[:, 1:, :-1]
    Tol3_add_x = Tol3[:, 1:, 1:] + Tol3[:, 1:, :-1]
    p_minus_x = p_pred[:, 1:, 1:] - p_pred[:, 1:, :-1]


    # f1_Res=1/(2*dx**2*mu_w*mu_g)*(Tol_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
    # f1_Res[:,:,q_g_place]+=q_g_1[:,None]
    # Res_f1=torch.sum(f1_Res**2)
    # plot_tx(f1_Res[1,:,:].detach().cpu().numpy(),"time","space","residual_f1")
    # print(Res_f1)

    # f2_Res=2*phi/dt*Sg_minus_t-1/(2*dx**2*mu_w*mu_g)*(Tol1_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol1_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
    # f2_Res[:,:,q_g_place]-=q_g_1[:,None]
    # Res_f2=torch.sum(f2_Res**2)
    # plot_tx(f2_Res[1,:,:].detach().cpu().numpy(),"time","space","residual_f2")
    # print(Res_f2)

    f3_Res=phi/dt*Sg_minus_t+1/(2*dx**2*mu_w)*(Tol2_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol2_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
    # f3_Res[:,:,q_g_place]+=q_g_1[:,None]
    Res_f3=torch.sum(f3_Res**2)
#     Res_f3_matrix=torch.sum(f3_Res**2,dim=0).flatten()
    # plot_tx(f3_Res[0,:,:].detach().cpu().numpy(),"time","space","residual_f3")
    # print(Res_f3)

    f4_Res=phi/dt*Sg_minus_t-1/(2*dx**2*mu_g)*(Tol3_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol3_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
    f4_Res[:,:,q_g_place]-=q_g_1[:,None]
    Res_f4=torch.sum(f4_Res**2)
#     Res_f4_matrix=torch.sum(f4_Res**2,dim=0).flatten()
    # plot_tx(f4_Res[0,:,:].detach().cpu().numpy(),"time","space","residual_f4")
    # print(Res_f4)



    return Res_f3,Res_f4


# def res_sp(Sg_1,p_1,K_1,q_g_1):

#     # Sg_pred=np.zeros((len(eta_Sg),N_rt,Nodes))
#     # p_pred=np.zeros((len(eta_Sg),N_rt,Nodes))
#     Sg_pred=Sg_1.reshape(len(Sg_1),N_rt,Nodes)
#     p_pred=p_in*p_1.reshape(len(Sg_1),N_rt,Nodes)

#     # Tol_add_x=np.zeros((len(eta_Sg),N_rt-1,N_rx))
#     # Sg_minus_t=np.zeros((len(eta_Sg),N_rt-1,N_rx-1))
#     # p_minus_x=np.zeros((len(eta_Sg),N_rt-1,N_rx))
#     K_1_expended = K_1.unsqueeze(1)
#     # Tol= (mu_g+(mu_w-mu_g)*Sg_pred)*K_1_expended
#     # Tol1=((mu_g+mu_w)*Sg_pred-mu_g)*K_1_expended
#     Tol2=(1-Sg_pred)*K_1_expended
#     Tol3=Sg_pred*K_1_expended

#     Sg_minus_t = Sg_pred[:, 1:, 1:-1] - Sg_pred[:, :-1, 1:-1]
#     # Tol_add_x = Tol[:, 1:, 1:] + Tol[:, 1:, :-1]
#     # Tol1_add_x = Tol1[:, 1:, 1:] + Tol1[:, 1:, :-1]
#     Tol2_add_x = Tol2[:, 1:, 1:] + Tol2[:, 1:, :-1]
#     Tol3_add_x = Tol3[:, 1:, 1:] + Tol3[:, 1:, :-1]
#     p_minus_x = p_pred[:, 1:, 1:] - p_pred[:, 1:, :-1]


#     # f1_Res=1/(2*dx**2*mu_w*mu_g)*(Tol_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
#     # f1_Res[:,:,q_g_place]+=q_g_1[:,None]
#     # Res_f1=torch.sum(f1_Res**2)
#     # plot_tx(f1_Res[1,:,:].detach().cpu().numpy(),"time","space","residual_f1")
#     # print(Res_f1)

#     # f2_Res=2*phi/dt*Sg_minus_t-1/(2*dx**2*mu_w*mu_g)*(Tol1_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol1_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
#     # f2_Res[:,:,q_g_place]-=q_g_1[:,None]
#     # Res_f2=torch.sum(f2_Res**2)
#     # plot_tx(f2_Res[1,:,:].detach().cpu().numpy(),"time","space","residual_f2")
#     # print(Res_f2)

#     f3_Res=phi/dt*Sg_minus_t+1/(2*dx**2*mu_w)*(Tol2_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol2_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
#     # f3_Res[:,:,q_g_place]+=q_g_1[:,None]
#     Res_f3=torch.sum(f3_Res**2)
#     plot_tx(f3_Res[0,:,:].detach().cpu().numpy(),"time","space","residual_f3")
#     print(Res_f3)

#     f4_Res=phi/dt*Sg_minus_t-1/(2*dx**2*mu_g)*(Tol3_add_x[:,:,1:]*p_minus_x[:,:,1:]-Tol3_add_x[:,:,:-1]*p_minus_x[:,:,:-1])
#     f4_Res[:,:,q_g_place]-=q_g_1[:,None]
#     Res_f4=torch.sum(f4_Res**2)
#     plot_tx(f4_Res[0,:,:].detach().cpu().numpy(),"time","space","residual_f4")
#     print(Res_f4)



#     return Res_f3,Res_f4

# # #float 64 still can't met the accuracy.
# # def res_bc(eta_Sg_1,eta_p_1,K_1,q_g_1):
# #     Sg_pred=(meanu_Sg+ (Psiu_Sg[:,:Nuterm_Sg] @ eta_Sg_1.T).T).reshape(len(eta_Sg_1),N_rt,Nodes)
# #     p_pred=p_in*(meanu_p+ (Psiu_p[:,:Nuterm_p] @ eta_p_1.T).T).reshape(len(eta_Sg_1),N_rt,Nodes)

# #     # Sg_minus_x=np.zeros((len(eta_Sg),N_rt))
# #     Sg_minus_x_0 = Sg_pred[:, :, 1] - Sg_pred[:, :, 0]
# #     Sg_minus_x_N = Sg_pred[:, :, -1] - Sg_pred[:, :, -2]

# #     p_minus_x_0 = p_pred[:, :, 1] - p_pred[:, :, 0]
# #     p_minus_x_N = p_pred[:, :, -1] - p_pred[:, :, -2]

# #     b1_Res=Sg_pred[:,:,0]-l*Sg_minus_x_0/dx-Sg_inf
# #     Res_b1=torch.sum(b1_Res**2)
# #     # plot_ln(b1_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     # print(Res_b1)

# #     b2_Res=Sg_pred[:,:,-1]+l*Sg_minus_x_N/dx-Sg_inf
# #     Res_b2=torch.sum(b2_Res**2)
# #     # plot_ln(b2_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     # print(Res_b2)

# #     # b3_Res=p_pred[:,:,0]-l*p_minus_x_0/dx-p_inf
# #     # Res_b3=torch.sum(b3_Res**2)
# #     # plot_ln(b3_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     # print(Res_b3)

# #     # b4_Res=p_pred[:,:,-1]+l*p_minus_x_N/dx-p_inf
# #     # Res_b4=torch.sum(b4_Res**2)
# #     # plot_ln(b4_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     # print(Res_b4)


# #     return Res_b1,Res_b2#,Res_b3,Res_b4

# # def res_bc_sp(Sg_1,p_1,K_1,q_g_1):
# #     Sg_pred=Sg_1.reshape(len(Sg_1),N_rt,Nodes)
# #     p_pred=p_in*p_1.reshape(len(Sg_1),N_rt,Nodes)

# #     # Sg_minus_x=np.zeros((len(eta_Sg),N_rt))
# #     Sg_minus_x_0 = Sg_pred[:, :, 1] - Sg_pred[:, :, 0]
# #     Sg_minus_x_N = Sg_pred[:, :, -1] - Sg_pred[:, :, -2]

# #     p_minus_x_0 = p_pred[:, :, 1] - p_pred[:, :, 0]
# #     p_minus_x_N = p_pred[:, :, -1] - p_pred[:, :, -2]

# #     b1_Res=Sg_pred[:,:,0]-l*Sg_minus_x_0/dx-Sg_inf
# #     Res_b1=torch.sum(b1_Res**2)
# #     plot_ln(b1_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     print(Res_b1)

# #     b2_Res=Sg_pred[:,:,-1]+l*Sg_minus_x_N/dx-Sg_inf
# #     Res_b2=torch.sum(b2_Res**2)
# #     plot_ln(b2_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     print(Res_b2)

# #     b3_Res=p_pred[:,:,0]-l*p_minus_x_0/dx-p_inf
# #     Res_b3=torch.sum(b3_Res**2)
# #     plot_ln(b3_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     print(Res_b3)

# #     b4_Res=p_pred[:,:,-1]+l*p_minus_x_N/dx-p_inf
# #     Res_b4=torch.sum(b4_Res**2)
# #     plot_ln(b4_Res[0,:].detach().cpu().numpy(),log_scale=False)
# #     print(Res_b4)


# #     return Res_b1,Res_b2,Res_b3,Res_b4

def res_np(eta_1,K_1,q_g_1):
    # For test
    eta_Sg_1 = eta_1[:(N_ts * Nuterm_Sg)].reshape(N_ts, Nuterm_Sg)
    eta_p_1 = eta_1[(N_ts * Nuterm_Sg):].reshape(N_ts, Nuterm_p)

    # Calculate Sg_pred and p_pred
    Sg_pred = (meanu_Sg + (Psiu_Sg[:, :Nuterm_Sg] @ eta_Sg_1.T).T).reshape(len(eta_Sg_1), N_rt, Nodes)
    p_pred = p_in * (meanu_p + (Psiu_p[:, :Nuterm_p] @ eta_p_1.T).T).reshape(len(eta_Sg_1), N_rt, Nodes)

    # Expand K_1 for broadcasting
    K_1_expended = np.expand_dims(K_1, axis=1)

    # Compute Tol values
    Tol2 = (1 - Sg_pred) * K_1_expended
    Tol3 = Sg_pred * K_1_expended

    # Calculate differences in time and space
    Sg_minus_t = Sg_pred[:, 1:, 1:-1] - Sg_pred[:, :-1, 1:-1]
    Tol2_add_x = Tol2[:, 1:, 1:] + Tol2[:, 1:, :-1]
    Tol3_add_x = Tol3[:, 1:, 1:] + Tol3[:, 1:, :-1]
    p_minus_x = p_pred[:, 1:, 1:] - p_pred[:, 1:, :-1]

    # Residual calculations
    f3_Res = phi / dt * Sg_minus_t + 1 / (2 * dx**2 * mu_w) * (Tol2_add_x[:, :, 1:] * p_minus_x[:, :, 1:] - Tol2_add_x[:, :, :-1] * p_minus_x[:, :, :-1])
    Res_f3 = np.sum(f3_Res**2)
    # print("Residual f3:", Res_f3)

    f4_Res = phi / dt * Sg_minus_t - 1 / (2 * dx**2 * mu_g) * (Tol3_add_x[:, :, 1:] * p_minus_x[:, :, 1:] - Tol3_add_x[:, :, :-1] * p_minus_x[:, :, :-1])
    f4_Res[:, :, q_g_place] -= q_g_1[:, None]
    Res_f4 = np.sum(f4_Res**2)
    # print("Residual f4:", Res_f4)


    return Res_f3+Res_f4

#k sampling
k,xi_k=samples_k(N_train,seed=0)

#training dataset
Sg,p,q_g = samples(N_train,N_rt,N_rx,k,q_g_m,0.9,1.1,seed=1)
assert np.max(Sg)<=1
print(np.max(Sg))

Psiu_Sg,meanu_Sg,val_Sg,cov_Sg=eigenpairs(Sg)

Psiu_p,meanu_p,val_p,cov_p=eigenpairs(p)

assert np.min(val_Sg)>=0
assert np.min(val_p)>=0

# plot_tx(cov_Sg,'Nt*Nx','Nt*Nx','cov_Sg_train')
# plot_tx(cov_p,'Nt*Nx','Nt*Nx','cov_p_train')


# xi=np.hstack((np.log(k),q_g.reshape(-1,1)))
xi=np.hstack((xi_k,q_g.reshape(-1,1)))

k_v,xi_k_v=samples_k(N_test,seed=2)
Sg_v,p_v,q_g_v = samples(N_test,N_rt,N_rx,k_v,q_g_m,0.9,1.1,seed=3)
xi_v=np.hstack((xi_k_v,q_g_v.reshape(-1,1)))
assert np.max(Sg_v)<=1
print(np.max(Sg_v))

# #for test
# k_c,xi_k_c=samples_k(1,seed=4)
# k_c=k_c.flatten()
# xi_k_c=xi_k_c.flatten()
# Sg_ts,p_ts =CO2_picard(N_rt,N_rx,k_c,q_g_c)
# assert np.max(Sg_ts)<=1
# print(np.max(Sg_ts))
# Sg_ts=Sg_ts.flatten()
# p_ts=p_ts.flatten()
# xi_ts = np.append(xi_k_c,q_g_c)

k_c,xi_k_c=samples_k(N_ts,seed=4)
Sg_ts,p_ts,q_g_c = samples(N_ts,N_rt,N_rx,k_c,q_g_m,0.9,1.1,seed=9)
xi_ts=np.hstack((xi_k_c,q_g_c.reshape(-1,1)))
assert np.max(Sg_ts)<=1
print(np.max(Sg_ts))

np.save('q_g_c.npy',q_g_c)
# #plot k_c
# np.save('k_c.npy', k_c)
# x_1 = np.arange(len(k_c[0]))
# plt.plot(x_1, k_c[0], label='Test1')
# plt.plot(x_1, k_c[1], label='Test2')
# plt.plot(x_1, k_c[2], label='Test3')

# # Adding the legend in the upper right
# plt.legend(loc='upper right', fontsize=14)
# plt.yscale('log')

# plt.xlabel('x', fontsize=14)
# plt.ylabel('k', fontsize=14)

# # Set tick parameters with font size 14
# plt.xticks(fontsize=14)
# plt.yticks(fontsize=14)

# # Saving the plot as a PNG file
# plt.savefig(f'k_c_test1.png')


# assert 1==2

eta_Sg = spl.lstsq(Psiu_Sg[:,:Nuterm_Sg], (Sg - meanu_Sg).T)[0].T
eta_p = spl.lstsq(Psiu_p[:,:Nuterm_p], (p - meanu_p).T)[0].T
eta_Sg_v = spl.lstsq(Psiu_Sg[:,:Nuterm_Sg], (Sg_v - meanu_Sg).T)[0].T
eta_p_v = spl.lstsq(Psiu_p[:,:Nuterm_p], (p_v - meanu_p).T)[0].T

initial_guess=np.zeros((N_ts*(Nuterm_Sg+Nuterm_p)))
result = minimize(res_np, initial_guess,args=(k_c,q_g_c), method='BFGS')

eta_Sg_pred=result.x[:(N_ts*Nuterm_Sg)].reshape(N_ts,Nuterm_Sg)
eta_p_pred=result.x[(N_ts*Nuterm_Sg):].reshape(N_ts,Nuterm_p)
Sg_pickle=(meanu_Sg+ (Psiu_Sg[:,:Nuterm_Sg] @ eta_Sg_pred.T).T)
p_pickle=(meanu_p+ (Psiu_p[:,:Nuterm_p] @ eta_p_pred.T).T)

np.save('Sg_hm_pickle_test1.npy', Sg_pickle)
np.save('p_hm_pickle_test1.npy', p_pickle)

print('rl2e_mean_Sg_0',rl2e_Sg(Sg_pickle[0],Sg_ts[0]))
print('rl2e_mean_p_0',rl2e_p(p_pickle[0],p_ts[0]))

print('rl2e_mean_Sg_1',rl2e_Sg(Sg_pickle[1],Sg_ts[1]))
print('rl2e_mean_p_1',rl2e_p(p_pickle[1],p_ts[1]))

print('rl2e_mean_Sg_2',rl2e_Sg(Sg_pickle[2],Sg_ts[2]))
print('rl2e_mean_p_2',rl2e_p(p_pickle[2],p_ts[2]))

error_Sg_hm=(Sg_pickle[0]-Sg_ts[0]).reshape(N_rt,Nodes)
error_p_hm=p_in/(10**6)*(p_pickle[0]-p_ts[0]).reshape(N_rt,Nodes)
np.save('error_Sg_hm_pickle_test1.npy', error_Sg_hm)
np.save('error_p_hm_pickle_test1.npy', error_p_hm)


# Create a figure with two subplots
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Plot error_Sg_hm as a heatmap
cax1 = axes[0].imshow(error_Sg_hm, origin='lower', aspect='auto', cmap='viridis')
axes[0].set_title('Error in Sg')
axes[0].set_xlabel('x')
axes[0].set_ylabel('t')
fig.colorbar(cax1, ax=axes[0])

# Plot error_p_hm as a heatmap
cax2 = axes[1].imshow(error_p_hm, origin='lower', aspect='auto', cmap='viridis')
axes[1].set_title('Error in p')
axes[1].set_xlabel('x')
axes[1].set_ylabel('t')
fig.colorbar(cax2, ax=axes[1])

# Display the plots
plt.tight_layout()

plt.savefig('error_heatmaps_test1.png', dpi=300, bbox_inches='tight')
plt.show()

assert 1==2

um_kl = Ogata_Banks(N_rt,N_rx,Dc,Vc)

N_mc = 50
Vs,lam,mean,V_mc,D_mc = eigenpairs(N_mc,min_coef=0.6,max_coef=1.4,seed=0)

srl = np.sqrt(lam)
Vs_kl = Vs[:,:N_kl].T.reshape((N_kl,N_rt,N_rx))
Vs_kl.shape

d1xVs,d2xVs,d1tVs,d1xmean,d2xmean,d1tmean = ADE_1D(Vs_kl,mean,BC_L = 'N')

EIP = Vs_kl.reshape((N_kl,-1)).T * srl[:N_kl]
SXD = d2xVs.reshape((N_kl,-1)).T * srl[:N_kl] # Matrix of terms in the second derivative of u with respect to x
FXD = d1xVs.reshape((N_kl,-1)).T * srl[:N_kl] # Product of eigenvalues and eigenfunctions of u
FTD = d1tVs.reshape((N_kl,-1)).T * srl[:N_kl] # First derivatives of u at time t=0

N_v = N_r-N_rx+2+N_m  # the vertical size of the matrix X in the equation X*eta=Y and size of the Y vector
X = np.zeros((N_v,N_kl))
residual = np.zeros(N_r-N_rx+2+N_m)

eta0 = np.zeros(N_kl)

Y = -resfunc(eta0,d1xVs, d2xVs, d1tVs, d1xmean, d2xmean, d1tmean, mean)
X = np.zeros((N_v,N_kl))
etaj = np.eye(N_kl)
for i in range(N_kl):
    X[:,i] = resfunc(etaj[i,:],d1xVs, d2xVs, d1tVs, d1xmean, d2xmean, d1tmean, mean) + Y

etaA = np.linalg.lstsq(X,Y,rcond=-1)[0]

uA = mean.flatten() + EIP @ etaA
uA_kl = uA.reshape((N_rt,N_rx))

err_kl = (np.abs(um_kl-uA_kl)/u_D)
err_ref = (np.abs(uA_kl - um_kl)/u_D)

(um_kl-uA_kl).max()

fig, ax = plt.subplots(1, 2,figsize=(12,6))
# PICKLE solution
uA = ax[0].pcolor(uA_kl, linewidths=2)
# Analytical solution
um = ax[1].pcolor(um_kl-uA_kl, linewidths=2)
ax[0].title.set_text(f'PICKLE Solution ({N_rt} by {N_rx})')
ax[1].title.set_text(r'Point Errror ($u_{true}-u_{PICKLE}$)')
ax[0].set_aspect('equal')
ax[1].set_aspect('equal')
divider1 = make_axes_locatable(ax[0])
cax1 = divider1.append_axes("right", size="5%", pad=0.2)
divider2 = make_axes_locatable(ax[1])
cax2 = divider2.append_axes("right", size="5%", pad=0.2)

fig.colorbar(uA, cax=cax1)
fig.colorbar(um, cax=cax2)
fig.tight_layout()

plt.savefig('../results/plots/1d_ade_pickle_120.png',dpi=600)

fig, ax = plt.subplots(1, 1,figsize=(6,6))
# PICKLE solution
uA = ax.pcolor(np.abs(uA_kl-um_kl), linewidths=2)
# Analytical solution
#um = ax[2].pcolor(np.abs(u_fem-um_kl), linewidths=2,vmin=0, vmax=0.02)
ax.title.set_text('PICKLE Point Error')
ax.set_aspect('equal')
divider = make_axes_locatable(ax)
cax = divider.append_axes("right", size="5%", pad=0.2)

fig.colorbar(uA, cax=cax)
fig.tight_layout()

print('PICKLE relative L2 error',rl2e(uA_kl,um_kl))
print('The mean absolute error: ',np.mean(np.abs(uA_kl-um_kl)))

#print(f'Regression ({Nuterm} terms) relative L2 error',rl2e(u_reg,u_ref))

with h5py.File(f'../results/mats/1d_ade_pickle_grid_{grid_size}.h5', 'w') as f:
     f.create_dataset(f'u_pickle_{grid_size}',data = uA_kl)

